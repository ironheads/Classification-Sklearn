{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\iron_\\scoop\\persist\\python\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\iron_\\scoop\\persist\\python\\lib\\site-packages (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\iron_\\scoop\\persist\\python\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\iron_\\scoop\\persist\\python\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\iron_\\scoop\\persist\\python\\lib\\site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\iron_\\scoop\\persist\\python\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\iron_\\scoop\\persist\\python\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Wall time: 1.29 s\n"
     ]
    }
   ],
   "source": [
    "# 检测环境是否安装\n",
    "%time !pip install pandas openpyxl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PVID</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>HR</th>\n",
       "      <th>RR</th>\n",
       "      <th>SBP</th>\n",
       "      <th>SPO2</th>\n",
       "      <th>DBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>PO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>68.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1</td>\n",
       "      <td>135.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>4816</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4816</th>\n",
       "      <td>4817</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4817</th>\n",
       "      <td>4818</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>4819</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4819</th>\n",
       "      <td>4820</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4388 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PVID   age  gender     HR    RR    SBP   SPO2   DBP    MAP  PO2\n",
       "0        1  65.0       1   68.0  16.0  101.0   94.0  50.0   61.0   79\n",
       "1        2  65.0       1   76.0  17.0  131.0   94.0  53.0   72.0   72\n",
       "2        3  65.0       1   87.0  16.0  114.0   96.0  41.0   60.0   92\n",
       "3        4  69.0       1  135.0  13.0  107.0   99.0  71.0   84.0   40\n",
       "4        5  72.0       0   80.0  18.0  122.0   95.0  29.0   63.0   82\n",
       "...    ...   ...     ...    ...   ...    ...    ...   ...    ...  ...\n",
       "4815  4816  85.0       1   88.0  20.0  102.0   95.0  58.0   72.0   36\n",
       "4816  4817  71.0       0   70.0  28.0  100.0  100.0  61.0   75.0  142\n",
       "4817  4818  71.0       0   74.0  30.0   87.0  100.0  58.0   68.0  259\n",
       "4818  4819  71.0       0   63.0  32.0  180.0  100.0  82.0  112.0  192\n",
       "4819  4820  71.0       0   89.0  25.0  121.0   82.0  68.0   85.0  156\n",
       "\n",
       "[4388 rows x 10 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_excel('dataset/regression_train.xlsx')\n",
    "test_dataset = pd.read_excel('dataset/regression_test.xlsx')\n",
    "## pre=processing\n",
    "# delete when the PVID exists more than one time\n",
    "dataset.drop_duplicates(subset=['PVID'],keep=False)\n",
    "test_dataset.drop_duplicates(subset=['PVID'],keep=False)\n",
    "# delete the nan lines\n",
    "dataset = dataset.dropna(axis=0,how='any')\n",
    "# delete the nan lines\n",
    "test_dataset = test_dataset.dropna(axis=0,how='any')\n",
    "# check whether the age is normal, clear the data with age == 91.4\n",
    "dataset['age'].unique()\n",
    "dataset=dataset.sort_values(by=['age'])\n",
    "dataset=dataset[dataset.age<90]\n",
    "\n",
    "test_dataset = test_dataset[test_dataset.age < 90]\n",
    "\n",
    "# check the gender\n",
    "dataset['gender'].unique()\n",
    "# check the HR\n",
    "dataset = dataset.sort_values(by=['HR'])\n",
    "dataset['HR'].unique()\n",
    "\n",
    "# check the RR\n",
    "dataset = dataset.sort_values(by=['RR'])\n",
    "dataset['RR'].unique()\n",
    "\n",
    "# check the SBP\n",
    "dataset = dataset.sort_values(by=['SBP'])\n",
    "dataset['SBP'].unique()\n",
    "\n",
    "# check the SPO2\n",
    "dataset = dataset.sort_values(by=['SPO2'])\n",
    "dataset['SPO2'].unique()\n",
    "\n",
    "#check the DBP\n",
    "dataset = dataset.sort_values(by=['DBP'])\n",
    "dataset['DBP'].unique()     \n",
    "\n",
    "#check the MAP\n",
    "dataset = dataset.sort_values(by=['MAP'])\n",
    "dataset['MAP'].unique()\n",
    "\n",
    "#sort by id\n",
    "dataset = dataset.sort_values(by=['PVID'])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\iron_\\scoop\\persist\\python\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\iron_\\scoop\\persist\\python\\lib\\site-packages (from scikit-learn) (1.21.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\iron_\\scoop\\persist\\python\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\iron_\\scoop\\persist\\python\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\iron_\\scoop\\persist\\python\\lib\\site-packages (from scikit-learn) (1.7.1)\n",
      "Wall time: 1.29 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PO2            1.000000\n",
       "SPO2_scaled    0.310284\n",
       "SPO2           0.310284\n",
       "MAP            0.041555\n",
       "MAP_scaled     0.041555\n",
       "SBP            0.021784\n",
       "SBP_scaled     0.021784\n",
       "gender         0.014617\n",
       "DBP_scaled    -0.009623\n",
       "DBP           -0.009623\n",
       "PVID          -0.016509\n",
       "age           -0.029970\n",
       "age_scaled    -0.029970\n",
       "HR            -0.061321\n",
       "HR_scaled     -0.061321\n",
       "RR            -0.128123\n",
       "RR_scaled     -0.128123\n",
       "Name: PO2, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time !pip install scikit-learn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# scale the age \n",
    "age_scale_param = scaler.fit(dataset['age'].values.reshape(-1, 1))\n",
    "dataset['age_scaled']=scaler.fit_transform(dataset['age'].values.reshape(-1, 1), age_scale_param)\n",
    "test_dataset['age_scaled']=scaler.fit_transform(test_dataset['age'].values.reshape(-1, 1), age_scale_param)\n",
    "# scale the HR\n",
    "HR_scale_param = scaler.fit(dataset['HR'].values.reshape(-1, 1))\n",
    "dataset['HR_scaled']=scaler.fit_transform(dataset['HR'].values.reshape(-1, 1), HR_scale_param)\n",
    "test_dataset['HR_scaled']=scaler.fit_transform(test_dataset['HR'].values.reshape(-1, 1), HR_scale_param)\n",
    "\n",
    "# scale the RR\n",
    "RR_scale_param = scaler.fit(dataset['RR'].values.reshape(-1, 1))\n",
    "dataset['RR_scaled']=scaler.fit_transform(dataset['RR'].values.reshape(-1, 1), RR_scale_param)\n",
    "test_dataset['RR_scaled']=scaler.fit_transform(test_dataset['RR'].values.reshape(-1, 1), RR_scale_param)\n",
    "# scale the SBP\n",
    "SBP_scale_param = scaler.fit(dataset['SBP'].values.reshape(-1, 1))\n",
    "dataset['SBP_scaled']=scaler.fit_transform(dataset['SBP'].values.reshape(-1, 1), SBP_scale_param)\n",
    "test_dataset['SBP_scaled']=scaler.fit_transform(test_dataset['SBP'].values.reshape(-1, 1), SBP_scale_param)\n",
    "# scale the SPO2\n",
    "SPO2_scale_param = scaler.fit(dataset['SPO2'].values.reshape(-1, 1))\n",
    "dataset['SPO2_scaled']=scaler.fit_transform(dataset['SPO2'].values.reshape(-1, 1), SPO2_scale_param)\n",
    "test_dataset['SPO2_scaled']=scaler.fit_transform(test_dataset['SPO2'].values.reshape(-1, 1), SPO2_scale_param)\n",
    "# scale the DBP\n",
    "DBP_scale_param = scaler.fit(dataset['DBP'].values.reshape(-1, 1))\n",
    "dataset['DBP_scaled']=scaler.fit_transform(dataset['DBP'].values.reshape(-1, 1), DBP_scale_param)\n",
    "test_dataset['DBP_scaled']=scaler.fit_transform(test_dataset['DBP'].values.reshape(-1, 1), DBP_scale_param)\n",
    "#scale the MAP\n",
    "MAP_scale_param = scaler.fit(dataset['MAP'].values.reshape(-1, 1))\n",
    "dataset['MAP_scaled']=scaler.fit_transform(dataset['MAP'].values.reshape(-1, 1), MAP_scale_param)\n",
    "test_dataset['MAP_scaled']=scaler.fit_transform(test_dataset['MAP'].values.reshape(-1, 1), MAP_scale_param)\n",
    "# find the corr factors\n",
    "corr_matrix = dataset.corr()\n",
    "\n",
    "corr_matrix['PO2'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "features = ['SPO2_scaled','MAP_scaled','SBP_scaled','age_scaled','gender','HR_scaled','RR_scaled']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------linear regression---------------------\n",
      "the mean squared error: 2403.0752\n",
      "the r2 score: -7.7610\n",
      "-----------------polynomial linear regression---------------------\n",
      "the mean squared error: 2302.8886\n",
      "the r2 score: -3.9246\n",
      "-----------------knn neighbors regression---------------------\n",
      "the mean squared error: 2735.7465\n",
      "the r2 score: -1.8245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from numpy import mean\n",
    "kfold_num=15\n",
    "kf= KFold(kfold_num,shuffle=True,random_state = 2)\n",
    "\n",
    "# linear regression\n",
    "print('-----------------linear regression---------------------')\n",
    "mse = []\n",
    "r2_scores = []\n",
    "for train,valid in kf.split(dataset):\n",
    "    train_x=dataset[features].iloc[train,:]\n",
    "    train_y = dataset['PO2'].iloc[train]\n",
    "    linearRegressionModel = linear_model.LinearRegression()\n",
    "    linearRegressionModel.fit(train_x,train_y)\n",
    "    valid_x = dataset[features].iloc[valid,:]\n",
    "    valid_y = dataset['PO2'].iloc[valid]\n",
    "    predict_valid_y = linearRegressionModel.predict(valid_x)\n",
    "    mse.append(mean_squared_error(predict_valid_y,valid_y))\n",
    "    # print(\"the mean squared error: %.4f\" % mse)\n",
    "    r2_scores.append(r2_score(predict_valid_y,valid_y))\n",
    "    # print(\"the r2 score: %.4f\" % mse)\n",
    "print(\"the mean squared error: %.4f\" % mean(mse))\n",
    "print(\"the r2 score: %.4f\" % mean(r2_scores))\n",
    "\n",
    "# Polynomial regression \n",
    "print('-----------------polynomial linear regression---------------------')\n",
    "mse = []\n",
    "r2_scores = []\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "for train,valid in kf.split(dataset):\n",
    "    train_x=dataset[features].iloc[train,:]\n",
    "    train_y = dataset['PO2'].iloc[train]\n",
    "    poly_reg = PolynomialFeatures(degree=2)\n",
    "    train_x_poly = poly_reg.fit_transform(train_x)\n",
    "    linearRegressionModel = linear_model.LinearRegression()\n",
    "    linearRegressionModel.fit(train_x_poly,train_y)\n",
    "    valid_x = dataset[features].iloc[valid,:]\n",
    "    valid_y = dataset['PO2'].iloc[valid]\n",
    "    valid_x_poly = poly_reg.fit_transform(valid_x)\n",
    "    predict_valid_y = linearRegressionModel.predict(valid_x_poly)\n",
    "    mse.append(mean_squared_error(predict_valid_y,valid_y))\n",
    "    # print(\"the mean squared error: %.4f\" % mse)\n",
    "    r2_scores.append(r2_score(predict_valid_y,valid_y))\n",
    "    # print(\"the r2 score: %.4f\" % mse)\n",
    "print(\"the mean squared error: %.4f\" % mean(mse))\n",
    "print(\"the r2 score: %.4f\" % mean(r2_scores))\n",
    "\n",
    "\n",
    "# KNN neighbors regressor\n",
    "print('-----------------knn neighbors regression---------------------')\n",
    "mse = []\n",
    "r2_scores = []\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "for train,valid in kf.split(dataset):\n",
    "    train_x=dataset[features].iloc[train,:]\n",
    "    train_y = dataset['PO2'].iloc[train]\n",
    "    model = KNeighborsRegressor(n_neighbors=4)\n",
    "    model.fit(train_x,train_y)\n",
    "    valid_x = dataset[features].iloc[valid,:]\n",
    "    valid_y = dataset['PO2'].iloc[valid]\n",
    "    predict_valid_y = model.predict(valid_x)\n",
    "    mse.append(mean_squared_error(predict_valid_y,valid_y))\n",
    "    # print(\"the mean squared error: %.4f\" % mse)\n",
    "    r2_scores.append(r2_score(predict_valid_y,valid_y))\n",
    "    # print(\"the r2 score: %.4f\" % mse)\n",
    "print(\"the mean squared error: %.4f\" % mean(mse))\n",
    "print(\"the r2 score: %.4f\" % mean(r2_scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------decision tree regression---------------------\n",
      "the mean squared error: 2247.3271\n",
      "the r2 score: -3.5903\n"
     ]
    }
   ],
   "source": [
    " # Decision Tree Regression\n",
    "print('-----------------decision tree regression---------------------')\n",
    "mse = []\n",
    "r2_scores = []\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "for train,valid in kf.split(dataset):\n",
    "    train_x=dataset[features].iloc[train,:]\n",
    "    train_y = dataset['PO2'].iloc[train]\n",
    "    model = DecisionTreeRegressor(max_depth=3)\n",
    "    model.fit(train_x,train_y)\n",
    "    valid_x = dataset[features].iloc[valid,:]\n",
    "    valid_y = dataset['PO2'].iloc[valid]\n",
    "    predict_valid_y = model.predict(valid_x)\n",
    "    mse.append(mean_squared_error(predict_valid_y,valid_y))\n",
    "    # print(\"the mean squared error: %.4f\" % mse)\n",
    "    r2_scores.append(r2_score(predict_valid_y,valid_y))\n",
    "    # print(\"the r2 score: %.4f\" % mse)\n",
    "print(\"the mean squared error: %.4f\" % mean(mse))\n",
    "print(\"the r2 score: %.4f\" % mean(r2_scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean squared error: 2260.3212\n",
      "the r2 score: -3.2012\n"
     ]
    }
   ],
   "source": [
    "# ada boost regression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "mse = []\n",
    "r2_scores = []\n",
    "for train,valid in kf.split(dataset):\n",
    "    train_x=dataset[features].iloc[train,:]\n",
    "    train_y = dataset['PO2'].iloc[train]\n",
    "    model = AdaBoostRegressor(n_estimators=2)\n",
    "    model.fit(train_x,train_y)\n",
    "    valid_x = dataset[features].iloc[valid,:]\n",
    "    valid_y = dataset['PO2'].iloc[valid]\n",
    "    predict_valid_y = model.predict(valid_x)\n",
    "    mse.append(mean_squared_error(predict_valid_y,valid_y))\n",
    "    # print(\"the mean squared error: %.4f\" % mse)\n",
    "    r2_scores.append(r2_score(predict_valid_y,valid_y))\n",
    "    # print(\"the r2 score: %.4f\" % mse)\n",
    "print(\"the mean squared error: %.4f\" % mean(mse))\n",
    "print(\"the r2 score: %.4f\" % mean(r2_scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean squared error: 2416.7210\n",
      "the r2 score: -2.0523\n"
     ]
    }
   ],
   "source": [
    "# random forest regreesion\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "mse = []\n",
    "r2_scores = []\n",
    "for train,valid in kf.split(dataset):\n",
    "    train_x=dataset[features].iloc[train,:]\n",
    "    train_y = dataset['PO2'].iloc[train]\n",
    "    model = RandomForestRegressor(n_estimators=50,random_state=0)\n",
    "    model.fit(train_x,train_y)\n",
    "    valid_x = dataset[features].iloc[valid,:]\n",
    "    valid_y = dataset['PO2'].iloc[valid]\n",
    "    predict_valid_y = model.predict(valid_x)\n",
    "    mse.append(mean_squared_error(predict_valid_y,valid_y))\n",
    "    # print(\"the mean squared error: %.4f\" % mse)\n",
    "    r2_scores.append(r2_score(predict_valid_y,valid_y))\n",
    "    # print(\"the r2 score: %.4f\" % mse)\n",
    "print(\"the mean squared error: %.4f\" % mean(mse))\n",
    "print(\"the r2 score: %.4f\" % mean(r2_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean squared error: 2469.2008\n",
      "the r2 score: -6.3500\n"
     ]
    }
   ],
   "source": [
    "# svm regression \n",
    "from sklearn.svm import SVR\n",
    "mse = []\n",
    "r2_scores = []\n",
    "for train,valid in kf.split(dataset):\n",
    "    train_x=dataset[features].iloc[train,:]\n",
    "    train_y = dataset['PO2'].iloc[train]\n",
    "    model = SVR(kernel='linear', gamma=0.01, C=1, epsilon=0.2)\n",
    "    model.fit(train_x,train_y)\n",
    "    valid_x = dataset[features].iloc[valid,:]\n",
    "    valid_y = dataset['PO2'].iloc[valid]\n",
    "    predict_valid_y = model.predict(valid_x)\n",
    "    mse.append(mean_squared_error(predict_valid_y,valid_y))\n",
    "    # print(\"the mean squared error: %.4f\" % mse)\n",
    "    r2_scores.append(r2_score(predict_valid_y,valid_y))\n",
    "    # print(\"the r2 score: %.4f\" % mse)\n",
    "print(\"the mean squared error: %.4f\" % mean(mse))\n",
    "print(\"the r2 score: %.4f\" % mean(r2_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean squared error: 2215.4417\n",
      "the r2 score: -3.0546\n"
     ]
    }
   ],
   "source": [
    "# MLP regression\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "mse = []\n",
    "r2_scores = []\n",
    "for train,valid in kf.split(dataset):\n",
    "    train_x=dataset[features].iloc[train,:]\n",
    "    train_y = dataset['PO2'].iloc[train]\n",
    "    model = MLPRegressor(max_iter=10000)\n",
    "    model.fit(train_x,train_y)\n",
    "    valid_x = dataset[features].iloc[valid,:]\n",
    "    valid_y = dataset['PO2'].iloc[valid]\n",
    "    predict_valid_y = model.predict(valid_x)\n",
    "    mse.append(mean_squared_error(predict_valid_y,valid_y))\n",
    "    # print(\"the mean squared error: %.4f\" % mse)\n",
    "    r2_scores.append(r2_score(predict_valid_y,valid_y))\n",
    "    # print(\"the r2 score: %.4f\" % mse)\n",
    "print(\"the mean squared error: %.4f\" % mean(mse))\n",
    "print(\"the r2 score: %.4f\" % mean(r2_scores))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f6f2a81bc1b513c085c284a11ed9b0e6b78b6a1486515fc3e3688750b2ae683"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
